{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9625a4ec-506b-4841-955e-fdb191ea1918",
   "metadata": {},
   "source": [
    "# Класификација на АДХД преку ЕЕГ сигнали (претпроцесирање)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4203d4a1-ce19-4b27-af16-5845f5282f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import warnings\n",
    "from autopreprocess_pipeline import *\n",
    "from autopreprocessing import dataset as ds\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv1D, MaxPool1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f43b4d-c3aa-4d1c-b186-47d88a64473b",
   "metadata": {},
   "source": [
    "### Вчитување, филтрирање на пациенти од интерес и отстранување артефакти (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264d4b54-e8d2-46c9-85ec-1f65a8652564",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/home/lukar/projects/eeg/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa9272",
   "metadata": {},
   "source": [
    "Податочното множество кое се користи во проектот е дел од опширната ЕЕГ база на податоци наречена Two Decades-Brainclinics Research Archive for Insights in Neurophysiologyсе (TDBRAIN), кое се состои од датотеки (кои се именувани со уникатна шифра на пациентот: participants_ID). Секоја датотека содржи најмалку 2 (во ретки случаеви и 3) снимања на пациент кој може да е здрав или да боледува од психичко растројство. Во овој случај не' интересираат само пациентите обележани со HEALTHY и ADHD. Датотеката 'derivatives', која претходно ги содржела пациентите со разни растројства е филтрирана и понатаму користена во кодот во следните чекори. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a17958-2b4f-4584-9ba5-af5daf276b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(main_path, 'TDBRAIN_ID_and_status.csv')) # convert the .xlsx file into a .csv file beforehand\n",
    "df_subset = df[['participants_ID', 'formal_status']] # only participants' ID and their status are needed from all columns\n",
    "df_filtered = df_subset[df_subset['formal_status'].isin(['HEALTHY', 'ADHD'])] # out of the 5+ statuses (classes), only healthy and adhd ones are needed\n",
    "\n",
    "filtered_file_path = '/home/lukar/projects/eeg/data/dataTDBRAIN_ID_and_status.csv'\n",
    "df_filtered.to_csv(filtered_file_path, index=False) # save the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34487c5d-cfa1-4636-afc4-aec35602afd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_ID</th>\n",
       "      <th>formal_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-87974617</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-87974621</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-87974665</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-87974709</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-87974841</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participants_ID formal_status\n",
       "0    sub-87974617       HEALTHY\n",
       "1    sub-87974621       HEALTHY\n",
       "2    sub-87974665       HEALTHY\n",
       "3    sub-87974709       HEALTHY\n",
       "4    sub-87974841       HEALTHY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff00949-c731-4d9e-803b-dcce8043bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Fp1,Fp2,F7,F3,Fz,F4,F8,FC3,FCz,FC4,T7,C3,Cz,C4,T8,CP3,CPz,CP4,P7,P3,Pz,P4,P8,O1,Oz,O2,VPVA,VNVB,HPHL,HNHR,Erbs,OrbOcc,Mass' # electrode names copied from one .csv eeg recordings file\n",
    "channel_names = text.split(',')  # split electrode names with commas\n",
    "channel_names = [f\"{name}\" for name in channel_names] # create a list of strings \n",
    "print(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_path = '/home/lukar/projects/eeg/data/derivatives' # Снимките од пациентите пред да се претпроцесираат/отстранат артефакти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437eee6-f0d4-4f2c-add9-3fced3b1d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcepath = folders_path\n",
    "preprocpath = '/home/lukar/projects/eeg/data/processed_subjects' # Филтрирани и исчистени снимки кои ќе се користат во понатамошната работа.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ea81a-a8ed-491d-8061-25fa5ca135bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "varargsin = {\n",
    "    'sourcepath' : folders_path,\n",
    "    'preprocpath' : preprocpath\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283edba",
   "metadata": {},
   "source": [
    "За претпроцесирање на податоците е искористен алгоритмот препорачан и тестиран од тимот на Brainclinics. Кодот е достапен заедно со податочното множество (на страната на Brainclinics), но оригиналната верзија е модифицирана согласно тековните верзии на наредбите во неа. Претпроцесирањето се извршува со објекти од класата dataset, кој ја содржи ЕЕГ снимката согласно форматирањето на Brainclinics, заедно со функции за корекција на артефакти и опција за зачувување на обработените снимки како .csv, .npy или .mat датотеки. \n",
    "\n",
    "За секое снимање, функцијата <code>autoprocess_standard</code> ќе ги детектира: \n",
    "1. ЕОГ (очни) артефакти - потекнуваат од движење на очите нагоре-надолу, лево-десно и од трепкање \n",
    "1. ЕМГ артефакти - потекнуваат од мускулна активност \n",
    "1. Сегментите со екстремна зашиленост (анг. <i>kurtosis</i>) \n",
    "1. Невообичаените скокови и разлики во максималниот позитивен и негативен напон (анг. <i>voltage swings</i>)\n",
    "1. Артефакти кои потекнуваат од трепкање\n",
    "\n",
    "Доколку повеќе од третина од податоците по канал е означена како артефакт, каналот е означен за да му се изврши интерполација врз основа на сигналите снимени од двете соседни електроди. Дополнително, каналите со шум низ целиот спектар и со ЕМГ примеси долж целиот сигнал се означуваат како неквалитетни. За каналите кај кои се јавуваат проблеми како празни вредности и преклопување со соседна електрода поради вишок спроводлив гел се врши интерполација со податоци од соседните канали.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002cada-7865-42f2-8ad0-048ee2ced2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "autopreprocess_standard(varargsin=varargsin) # Функција за отстранување на артефакти предложена од научниците кои го составиле податочното множество.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e4304-afe0-4932-b557-6a38bfd98378",
   "metadata": {},
   "source": [
    "### Поделба на пациенти и сегментирање на сигналите "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42e9fb-be48-40ba-a9fa-6780559c8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_string_from_end(string, char, flip): # Помошна функција за форматирање на имињата на датотеките кои ќе се добијат по сегментирањето на податоците. \n",
    "    \n",
    "    index = string.rfind(char)\n",
    "    if not flip:\n",
    "        if index != -1:\n",
    "            chopped_string = string[index:]\n",
    "        else:\n",
    "            chopped_string = string\n",
    "\n",
    "        return chopped_string\n",
    "    else:\n",
    "        if index != -1:\n",
    "            chopped_string = string[:index]\n",
    "        else:\n",
    "            chopped_string = string\n",
    "\n",
    "        return chopped_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45463c97",
   "metadata": {},
   "source": [
    "За да се добијат доволно поединечни точки во податочното множество, наместо да се користат целите ЕЕГ снимки, тие се сегментирани со преклопувачки лизгачки прозорец.\n",
    "Секое снимање на пациент трае 120 секунди, и снимките се семплирани со фреквенција од 500 Hz. Ова значи дека секоја (целосна) снимка ќе има 60000 податочни точки, и во конечната верзија на проектот таа ќе биде сегментирана со прозорец од големина 5000 точки и преклоп од 500 точки.\n",
    "\n",
    "Бројот на сегменти кој го добиваме од секоја снимка е даден со следната формула:\n",
    "$$\n",
    "    N = \\left\\lfloor \\frac{T - W}{W - O} \\right\\rfloor + 1 \\\\ \n",
    "$$\n",
    "Каде: <br><br>\n",
    "$\n",
    "    W - \\text{Големина на прозорец} \\\\\n",
    "    T - \\text{Вкупен број временски точки во оригинална снимка} \\\\\n",
    "    O - \\text{Должина на преклопување} \\\\\n",
    "$\n",
    "<br><br>\n",
    "\n",
    "Ова соодветствува на: $t_{window} = \\frac{5000}{500Hz} = 10s$, и преклоп од $1s$\n",
    "\n",
    "Ако ги замениме вредностите кои ги одбравме за нашите податоци, тогаш се добива $N = 13$ како број на нови сегменти добиени од секоја оригинална снимка. \n",
    "<br>\n",
    "НАПОМЕНА: во текот на изработката на проектот се пробувани различни големини за лизгачкиот прозорец со цел да се балансира меѓу добивката на големината на податочното множество, и квалитетот/информациите кои ги содржи секоја податочна точка. Доколку искористиме премал чекор и прозорец, ќе имаме голем број податоци но тие ќе носат помалку информации во секоја точка, додека во обратниот случај податоците ќе се поквалитетни/информативни, но ќе имаме премалку за тренирање добар модел, и носење на значаен заклучок. Заклучено е дека големините на сегмените опишани горе се најдобри, но бидејќи тетратката е користена многу пати, како и поединечните ќелии во неа, можно е output-ите на некои ќелии да не се совпаѓаат со други. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba65b5-84ce-4e4f-8f7c-6e7d0f74f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_csv(path_to_file, path_to_dir, window_length=5000, overlap=500):\n",
    "\n",
    "    df = pd.read_csv(path_to_file)\n",
    "    \n",
    "    df = df.drop(columns=['artifacts', 'VEOG', 'HEOG', 'Erbs', 'OrbOcc', 'Mass'], axis=1) # Се отстрануваат колоните кои се останати од иницијалното чистење на артефактите во сигналите\n",
    "    i=0 \n",
    "    for i in range(13):\n",
    "        sub_df = df.iloc[i*overlap : i*overlap + window_length]\n",
    "        i+=1\n",
    "        subject_name = chop_string_from_end(path_to_file,\"/\", flip=0)\n",
    "        clean_name = chop_string_from_end(subject_name,\"eeg_csv\",flip=1)\n",
    "\n",
    "        seg_path = path_to_dir + \"/\" + clean_name + \"_seg_\" + str(i) + \".csv\"\n",
    "\n",
    "        \n",
    "        \n",
    "        sub_df.to_csv(seg_path)       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63957886-f7ce-45d6-9024-1742d1713377",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir = \"/home/lukar/projects/eeg/data/processed_subjects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8375180-2340-4351-890f-dfa2dbbfc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_csv_files(directory): # помошна функција која ни овозможува да добиеме листа од имиња на датотеки кои ќе бидат сегментирани\n",
    "    \"\"\"\n",
    "    Recursively searches for .csv files in the given directory and its subdirectories.\n",
    "    Returns a list of paths to the found .csv files.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "                \n",
    "    return csv_files            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637c436d-109d-45c9-bf8f-8100eee724c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = df_filtered.set_index('participants_ID')['formal_status'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0acc2",
   "metadata": {},
   "source": [
    "Прво, целосните снимки (датотеки) ги делиме на 2 - една датотека со пациенти кои се дијагностицирани со АДХД, и дадотека на пациенти без дијагноза. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f94ff2-0572-4063-8dcd-dcca9e0aa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/lukar/projects/eeg/data/processed_subjects'\n",
    "target_dir_adhd = '/home/lukar/projects/eeg/data/adhd'\n",
    "target_dir_healthy = '/home/lukar/projects/eeg/data/healthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c4b81-de40-47c4-85a6-0c6cbe369f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for subject in os.listdir(source_dir): # преместување на измешани пациенти во различни датотеки \n",
    "   \n",
    "\n",
    "    if df_dict[subject] == \"HEALTHY\":\n",
    "        shutil.move(os.path.join(source_dir, subject), target_dir_healthy)\n",
    "    elif df_dict[subject] == \"ADHD\":\n",
    "        shutil.move(os.path.join(source_dir, subject), target_dir_adhd)   \n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e4698a-7f50-432a-a64a-c2b0f139efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_dir = os.listdir(target_dir_adhd)\n",
    "healthy_dir = os.listdir(target_dir_healthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf46a1",
   "metadata": {},
   "source": [
    "Ги чуваме патеките на секоја датотека на пациент, понатаму ќе ги поделиме во множества за тренирање, тестирање, и валидација "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb3fdd9a-1255-4643-b2e5-314b0cc3e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_dir = [os.path.join(target_dir_adhd,subject) for subject in adhd_dir]\n",
    "healthy_dir = [os.path.join(target_dir_healthy,subject) for subject in healthy_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f85cf0ae-e40b-43ba-982f-a6ef0fa2abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '/home/lukar/projects/eeg/data/training'\n",
    "validation_path = '/home/lukar/projects/eeg/data/validation'\n",
    "testing_path = '/home/lukar/projects/eeg/data/testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a2e34",
   "metadata": {},
   "source": [
    "Во податочното множество, пациентите се поделени на следниот начин:\n",
    " - Tренирање: 31 HEALTHY, 31 ADHD \n",
    " - Валидација: 4 HEALTHY, 4 ADHD\n",
    " - Тестирање: 4 HEALTHY, 4 ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2408d-0dc3-4b20-a731-de0c3c26b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(healthy_dir)): \n",
    "    if i<31: # alternate between healthy and adhd subject and add 31 samples of each into training data \n",
    "        shutil.move(healthy_dir[i], training_path)\n",
    "        shutil.move(adhd_dir[i], training_path)\n",
    "    elif i >= 31 and i < 35:  # alternate between healthy and adhd subject and add 4 samples of each into validation data \n",
    "        shutil.move(healthy_dir[i], validation_path)\n",
    "        shutil.move(adhd_dir[i], validation_path)\n",
    "    elif i>=35 and i < 39: # alternate between healthy and adhd subject and add 4 samples of each into testing data\n",
    "        shutil.move(healthy_dir[i], testing_path)\n",
    "        shutil.move(adhd_dir[i], testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc04501-72ff-4471-ac7a-42a783e34855",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv_files = find_csv_files(training_path) # ги чуваме патеките за снимањата на секој пациент \n",
    "validation_csv_files = find_csv_files(validation_path)\n",
    "testing_csv_files = find_csv_files(testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac9a5c-0d71-4e57-b7b3-a54842ca0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_segmented_path =   \"/home/lukar/projects/eeg/data/training_segmented\" # ги чуваме сегментираните датотеки во посебни директориуми \n",
    "validation_segmented_path =  \"/home/lukar/projects/eeg/data/validation_segmented\"\n",
    "testing_segmented_path = \"/home/lukar/projects/eeg/data/testing_segmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a9d14c2-e453-4409-80a2-5048cb9e6226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 124/124 [17:46<00:00,  8.60s/it]\n"
     ]
    }
   ],
   "source": [
    "for training_file in tqdm(training_csv_files):\n",
    "    segment_csv(path_to_file = training_file, path_to_dir = training_segmented_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d5d7e2c-d140-4865-a965-c458c2ea7139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 36/36 [05:06<00:00,  8.52s/it]\n"
     ]
    }
   ],
   "source": [
    "for validation_file in tqdm(validation_csv_files):\n",
    "    segment_csv(path_to_file = validation_file, path_to_dir = validation_segmented_path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb0cf8f4-60b6-4701-b7f4-1065ee6a6fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 34/34 [04:48<00:00,  8.48s/it]\n"
     ]
    }
   ],
   "source": [
    "for testing_file in tqdm(testing_csv_files):\n",
    "    segment_csv(path_to_file = testing_file, path_to_dir = testing_segmented_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11985b6-7ba6-42e2-aaa1-f2f51f5e4c53",
   "metadata": {},
   "source": [
    "### Извлекување на карактеристики и поделба во множества за тренирање, тестирање и валидација"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c69aa0",
   "metadata": {},
   "source": [
    "Во овој дел се извлекуваат статистички и спектрални обележја од секој сегмент, и се зачувуваат како .npy датотеки кои ќе се користат во понатамошната анализа и класификација. \n",
    "\n",
    "Изборот на обележјата е инспириран од слични истражувања во оваа област:\n",
    "\n",
    "- Коефициент на асиметрија, зашиленост [E. Sathiya, T. D. Rao, and T. S. Kumar, “Gabor filter-based statistical features for ADHD detection,” Front. Hum. Neurosci., vol. 18, p. 1369862, Apr. 2024, doi: <a>10.3389/fnhum.2024.1369862.</a>]\n",
    "- Јортови параметри [B. Hjorth, “EEG analysis based on time domain properties,” Electroencephalography and Clinical Neurophysiology, vol. 29, no. 3, pp. 306–310, Sep. 1970, doi: <a>10.1016/0013-4694(70)90143-4.</a>]\n",
    "- Моќности на алфа, бета, гама, делта и тета опсезите [M. Moghaddari, M. Z. Lighvan, and S. Danishvar, “Diagnose ADHD disorder in children using convolutional neural network based on continuous mental task EEG,” Computer Methods and Programs in Biomedicine, vol. 197, p. 105738, Dec. 2020, doi: <a>10.1016/j.cmpb.2020.105738.</a>]\n",
    "- Нелинеарни обележја (фрактална димензија според алгоритмите на: Хигучи, Јорт и Петросијан) [M. R. Mohammadi, A. Khaleghi, A. M. Nasrabadi, S. Rafieivand, M. Begol, and H. Zarafshan, “EEG classification of ADHD and normal children using non-linear features and neural network,” Biomed. Eng. Lett., vol. 6, no. 2, pp. 66–73, May 2016, doi: <a>10.1007/s13534-016-0218-2.</a>]\n",
    "- Мерки за спектрална ентропија [T. Inouye et al., “Quantification of EEG irregularity by use of the entropy of the power spectrum,” Electroencephalography and Clinical Neurophysiology, vol. 79, no. 3, pp. 204–210, Sep. 1991, doi: <a>10.1016/0013-4694(91)90138-T.</a>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a81fef-ffb2-4ead-b5cc-bfe59fc9276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filepaths = [os.path.join(training_segmented_path,file) for file in os.listdir(training_segmented_path)]\n",
    "validation_filepaths = [os.path.join(validation_segmented_path,file) for file in os.listdir(validation_segmented_path)]\n",
    "testing_filepaths = [os.path.join(testing_segmented_path,file) for file in os.listdir(testing_segmented_path)]\n",
    "\n",
    "X_train = []\n",
    "X_val = []\n",
    "X_test = [] \n",
    "\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ec307",
   "metadata": {},
   "source": [
    "Конкретно, статистичките обележја кои се извлекуваат од секој сигнал се следните: \n",
    "1. Средна вредност \n",
    "1. Ефективна вредност (RMS)\n",
    "1. Стандардна девијација \n",
    "1. Коефициент на  асиметрија (анг. <i>skewness</i>) \n",
    "1. Зашиленост (анг. <i>kurtosis</i>)\n",
    "\n",
    "Јортовите параметри: \n",
    "1. Активност - мерка за варијансата на амплитудата на сигналот \n",
    "1. Мобилност - мерката за стандардната девијација на нагибот (изводот) на сигналот во однос на стандардната девијација на амплитудата\n",
    "1. Комплексност -  сооднос меѓу мобилноста на првиот извод на сигналот и мобилноста на самиот сигнал\n",
    "\n",
    "Спектрални обележја:\n",
    "1. Алфа-моќност\n",
    "1. Бета-моќност \n",
    "1. Делта-моќност \n",
    "1. Тета-моќност\n",
    "1. Гама-моќност \n",
    "1. Однос на тета и бета моќности \n",
    "1. Шенонова ентропија\n",
    "1. Спектрална ентропија за тета и бета опсези \n",
    "1. Вејвлет ентропија\n",
    "\n",
    "Нелинеарни обележја:\n",
    "1. Фрактална димензија според Хичуги \n",
    "1. Фрактална димензија според Кац \n",
    "1. Фрактална димензија според Петросијан \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f3a36414-a66e-411f-97ed-5d87a5fbaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import entropy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def wavelet_entropy(segment, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "    entropy_list = []\n",
    "    for coeff in coeffs:\n",
    "        coeff = np.abs(coeff)\n",
    "        norm_coeff = coeff / np.sum(coeff)\n",
    "        entropy_list.append(entropy(norm_coeff))\n",
    "    return np.mean(entropy_list)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kurtosis, skew, entropy\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import simpson\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import log2, mean, sqrt\n",
    "from math import log10\n",
    "\n",
    "def compute_bandpower(segment, fs, band):\n",
    "    freqs, psd = welch(segment, fs)\n",
    "    band_freqs = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    band_power = simpson(y=psd[band_freqs], x=freqs[band_freqs])\n",
    "    return band_power, psd, freqs\n",
    "\n",
    "def hjorth_params(segment):\n",
    "    # Hjorth Activity\n",
    "    activity = np.var(segment)\n",
    "    \n",
    "    # Hjorth Mobility\n",
    "    derivative = np.diff(segment)\n",
    "    mobility = np.std(derivative) / np.std(segment)\n",
    "    \n",
    "    # Hjorth Complexity\n",
    "    second_derivative = np.diff(derivative)\n",
    "    complexity = (np.std(second_derivative) / np.std(derivative)) / mobility\n",
    "    \n",
    "    return activity, mobility, complexity\n",
    "\n",
    "def spectral_entropy(psd):\n",
    "    psd_norm = psd / np.sum(psd)\n",
    "    return entropy(psd_norm)\n",
    "\n",
    "def shannon_entropy(segment):\n",
    "    prob_dist, _ = np.histogram(segment, bins=256, density=True)\n",
    "    prob_dist = prob_dist[prob_dist > 0]\n",
    "    return -np.sum(prob_dist * np.log2(prob_dist))\n",
    "\n",
    "def higuchi_fd(segment, k_max):\n",
    "    L = []\n",
    "    x = np.asarray(segment)\n",
    "    N = len(x)\n",
    "\n",
    "    for k in range(1, k_max):\n",
    "        Lk = 0\n",
    "        for m in range(k):\n",
    "            Lmk = 0\n",
    "            for i in range(1, int(np.floor((N - m) / k))):\n",
    "                Lmk += np.abs(x[m + i * k] - x[m + (i - 1) * k])\n",
    "            Lmk = Lmk * (N - 1) / (int(np.floor((N - m) / k)) * k)\n",
    "            Lk += Lmk\n",
    "        L.append(np.log(Lk / k))\n",
    "\n",
    "    return np.polyfit(np.log(range(1, k_max)), L, 1)[0]\n",
    "\n",
    "    \n",
    "def katz_fd(segment):\n",
    "    L = np.sum(np.sqrt(np.ediff1d(segment) ** 2 + 1))\n",
    "    d = np.max(np.abs(segment - segment[0]))\n",
    "    N = len(segment)\n",
    "    return log10(L) / (log10(d) + log10(N))\n",
    "\n",
    "def petrosian_fd(segment):\n",
    "    n = len(segment)\n",
    "    diff = np.diff(segment)\n",
    "    N_delta = np.sum(diff[1:] * diff[:-1] < 0)\n",
    "    return log10(n) / (log10(n) + log10(n / (n + 0.4 * N_delta)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa7c9c-a350-49d7-80f4-e26dfe74fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(df, fs,eo):\n",
    "    feature_list = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        segment = df[column].values\n",
    "        # Compute time-domain features\n",
    "        mean_val = np.mean(segment)\n",
    "        std_val = np.std(segment)\n",
    "        rms_val = np.sqrt(np.mean(segment**2))\n",
    "        kurtosis_val = kurtosis(segment)\n",
    "        skewness_val = skew(segment)\n",
    "\n",
    "        # Compute Hjorth parameters\n",
    "        activity, mobility, complexity = hjorth_params(segment)\n",
    "\n",
    "        # Compute Shannon's entropy\n",
    "        shannon_entropy_val = shannon_entropy(segment)\n",
    "\n",
    "        # Compute band powers and PSD entropy\n",
    "        delta_power, _, _ = compute_bandpower(segment, fs, [0.5, 4])\n",
    "        theta_power, psd_t, freqs = compute_bandpower(segment, fs, [4, 8])\n",
    "        alpha_power, _, _ = compute_bandpower(segment, fs, [8, 13])\n",
    "        beta_power, psd_b, _ = compute_bandpower(segment, fs, [13, 30])\n",
    "        gamma_power, _, _ = compute_bandpower(segment, fs, [30, 100])\n",
    "\n",
    "        \n",
    "        \n",
    "        # Compute spectral entropy for theta and beta bands\n",
    "        spectral_entropy_theta = spectral_entropy(psd_t)\n",
    "        spectral_entropy_beta = spectral_entropy(psd_b)\n",
    "\n",
    "        # Compute wavelet entropy\n",
    "        wavelet_entropy_val = wavelet_entropy(segment)\n",
    "        \n",
    "        # Compute theta to beta power ratio\n",
    "        theta_beta_ratio = theta_power/beta_power\n",
    "\n",
    "        # Combine all features\n",
    "        features = [\n",
    "            mean_val, std_val, rms_val, kurtosis_val, skewness_val,\n",
    "            activity, mobility, complexity, shannon_entropy_val, spectral_entropy_theta, spectral_entropy_beta,\n",
    "            delta_power, theta_power, alpha_power, beta_power, gamma_power, wavelet_entropy_val, theta_beta_ratio\n",
    "        ]\n",
    "        feature_list.append(features)\n",
    "\n",
    "    feature_array = np.array(feature_list)\n",
    "\n",
    "    \n",
    "    features_flattened = feature_array.flatten()\n",
    "\n",
    "    \n",
    "   \n",
    "    return features_flattened\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d91a8",
   "metadata": {},
   "source": [
    "За патеките во директориумите за тренирање, валидација, и тестирање, ги пресметуваме вредностите за обележјата наведени погоре, податоците ги зачувуваме во .npy датотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67511c-6fcf-4330-a035-e0c2f7ae5be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 13640/13640 [15:17<00:00, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded! Training set: 13640, labels: 13640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(training_filepaths): \n",
    "\n",
    "    \n",
    "    index = csv.rfind(\"/\")\n",
    "    subject_name = csv[index+1:]\n",
    "    subject_index = subject_name.find(\"_\")\n",
    "    subject_name = subject_name[:subject_index]\n",
    "   \n",
    "\n",
    "    if df_dict[subject_name] == \"HEALTHY\":\n",
    "        y_train.append(0)\n",
    "    elif df_dict[subject_name] == \"ADHD\":\n",
    "         y_train.append(1)\n",
    "\n",
    "    \n",
    "    segment = pd.read_csv(csv)\n",
    "    segment = segment.drop(columns = ['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "    \n",
    "    feature_file = extract_features(df = segment,fs = 500)\n",
    "    \n",
    "\n",
    "    \n",
    "    X_train.append(feature_file)\n",
    "\n",
    "print (f\"Training data loaded! Training set: {len(X_train)}, labels: {len(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486558e-2c69-4b23-a6ef-0335121b3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3960/3960 [04:23<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data loaded! Validation set: 3960, labels: 3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(validation_filepaths): \n",
    "    \n",
    "    index = csv.rfind(\"/\")\n",
    "    subject_name = csv[index+1:]\n",
    "    subject_index = subject_name.find(\"_\")\n",
    "    subject_name = subject_name[:subject_index]\n",
    "   \n",
    "\n",
    "    if df_dict[subject_name] == \"HEALTHY\":\n",
    "        y_val.append(0)\n",
    "    elif df_dict[subject_name] == \"ADHD\":\n",
    "         y_val.append(1)\n",
    "\n",
    "    \n",
    "    segment = pd.read_csv(csv)\n",
    "    segment = segment.drop(columns = ['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "    \n",
    "    feature_file = extract_features(df = segment,fs = 500)\n",
    "        \n",
    "    \n",
    "        \n",
    "    X_val.append(feature_file)\n",
    "\n",
    "print (f\"Validation data loaded! Validation set: {len(X_val)}, labels: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba29fc-43e5-4a6a-b66b-5b69254ff523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3740/3740 [04:10<00:00, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data loaded! Testing set: 3740, labels: 3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for csv in tqdm(testing_filepaths): \n",
    "    \n",
    "    index = csv.rfind(\"/\")\n",
    "    subject_name = csv[index+1:]\n",
    "    subject_index = subject_name.find(\"_\")\n",
    "    subject_name = subject_name[:subject_index]\n",
    "   \n",
    "\n",
    "    if df_dict[subject_name] == \"HEALTHY\":\n",
    "        y_test.append(0)\n",
    "    elif df_dict[subject_name] == \"ADHD\":\n",
    "         y_test.append(1)\n",
    "\n",
    "    \n",
    "    segment = pd.read_csv(csv)\n",
    "    segment = segment.drop(columns = ['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "    feature_file = extract_features(df = segment, fs = 500)\n",
    "  \n",
    "    X_test.append(feature_file)\n",
    "\n",
    "print (f\"Testing data loaded! Testing set: {len(X_test)}, labels: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "56cee318-a34f-4266-bee2-62a9cfa5e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"X_val.npy\", X_val)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "np.save(\"y_val.npy\", y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
